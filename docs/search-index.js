znaiSearchData = [["@@index@@liftwizard","","","Liftwizard","Liftwizard is a collection of bundles and add ons for Dropwizard the Java framework for writing web services There are very few dependencies between the bundles so you can pick and choose the ones you want Module groups The bundles can be loosely grouped into categories Dropwizard configuration JSON serialization deserialization Servlet client server logging GraphQL utility Reladomo ORM integration for Dropwizard Other Dropwizard utility Guide structure In this guide we ll start with the application which is a maven module that s part of the main Dropwizard repository We ll gradually turn it into an application with an identical service api that uses as many Liftwizard features as possible","dropwizard example liftwizard example"],["introduction@@liftwizard@@","Introduction","Liftwizard","","Liftwizard is a collection of bundles and add ons for Dropwizard the Java framework for writing web services There are very few dependencies between the bundles so you can pick and choose the ones you want The bundles can be loosely grouped into categories Dropwizard configuration and bundles Jackson JSON serialization deserialization Servlet client server logging Reladomo ORM integration for Dropwizard JUnit 4 and JUnit 5 test utilities",""],["configuration@@environment-variable-substitution@@in-example-applications","Configuration","Environment Variable Substitution","in example applications","The supports environment variable substitution inside Dropwizard configuration files In the example applications environment variable substitution is used for We can see this in action by running the command with and without the environment variable set","EnvironmentConfigBundle defaultName template Hello %s defaultName $ DW_DEFAULT_NAME Stranger render $ java jar target liftwizard example 0 1 0 jar render example yml include default INFO 2020 05 02 03 07 41 910 com example helloworld cli RenderCommand DEFAULT > Hello Stranger $ DW_DEFAULT_NAME EnvSubstitution java jar target liftwizard example 0 1 0 jar render example yml include default INFO 2020 05 02 03 08 05 685 com example helloworld cli RenderCommand DEFAULT > Hello EnvSubstitution"],["configuration@@environment-variable-substitution@@in-dropwizard-example","Configuration","Environment Variable Substitution","in dropwizard-example","","@Override public void initialize Bootstrap<HelloWorldConfiguration> bootstrap Enable variable substitution with environment variables bootstrap setConfigurationSourceProvider new SubstitutingSourceProvider bootstrap getConfigurationSourceProvider new EnvironmentVariableSubstitutor false"],["configuration@@environment-variable-substitution@@in-liftwizard-example","Configuration","Environment Variable Substitution","in liftwizard-example","lives in the module","@Override public void initialize Bootstrap<HelloWorldConfiguration> bootstrap bootstrap addBundle new EnvironmentConfigBundle EnvironmentConfigBundle liftwizard bundle environment config <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard bundle environment config< artifactId> < dependency>"],["configuration@@json5-configuration@@configuration-through-json5-instead-of-yaml","Configuration","Json5 Configuration","Configuration through json5 instead of yaml","Dropwizard s configuration is specified in yaml by default While yaml has nice properties you may prefer json or some other format Dropwizard s documentation claims If your configuration file doesn t end in yml or yaml Dropwizard tries to parse it as a JSON file This is easily disproved by renaming example yml to example json and trying to run the application It will incorrectly start without error Since json syntax is a subset of yml syntax you can go ahead and convert your configuration file to json without changing the file extension from yaml or yml However this approach doesn t prevent you from accidentally using yaml syntax You can change your application to use json for its configuration using uses json5 syntax by default using optional features in Jackson So you ll still be able to include comments inside your configuration files After adding the bundle you ll have to convert your configuration files to json5 and rename them So becomes Configuration files used in tests must be converted as well So becomes","JsonConfigurationFactoryFactory @Override public void initialize Bootstrap<HelloWorldConfiguration> bootstrap bootstrap setConfigurationFactoryFactory new JsonConfigurationFactoryFactory<> JsonConfigurationFactoryFactory example yml example json5 DropwizardAppRule DropwizardAppExtension src test resources test example yml src test resources test example json5"],["configuration@@json5-configuration@@adding-the-dependency","Configuration","Json5 Configuration","Adding the dependency","lives in the module","JsonConfigurationFactoryFactory liftwizard configuration factory json <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard configuration factory json< artifactId> < dependency>"],["configuration@@ConfigLoggingBundle@@adding-the-dependency","Configuration","ConfigLoggingBundle","Adding the dependency","The logs the Dropwizard configuration using SLF4J It serializes the in memory configuration object to json and logs that json not the contents of the original configuration file The output contains default values set by constructors that were not specified in the original configuration file To turn it on add to the list of registered bundles Now will log something like this on startup Note that the section at the end was not specified in It comes from serializing the output of This output can be helpful for fleshing out the configuration file with default options Including redundant defaults makes it easier to edit the configuration by hand It s easier to flip a boolean flag from to than to first figure out where in the configuration file it belongs and the exact spelling of its key The also logs the default configuration at the level It does this by instantiating a new copy of the configuration class using the default no arg constructor serializing it to json and logging it The default configuration output can be useful for finding redundant configuration to remove lives in the module","ConfigLoggingBundle ConfigLoggingBundle @Override public void initialize Bootstrap<HelloWorldConfiguration> bootstrap bootstrap setConfigurationFactoryFactory new JsonConfigurationFactoryFactory<> bootstrap addBundle new EnvironmentConfigBundle bootstrap addBundle new ObjectMapperBundle bootstrap addBundle new ConfigLoggingBundle StructuredArgumentsMDCLogger structuredLogger new StructuredArgumentsMDCLogger bootstrap getObjectMapper bootstrap addBundle new JerseyHttpLoggingBundle structuredLogger bootstrap addBundle new ClockBundle bootstrap addBundle new UUIDBundle bootstrap addBundle new H2Bundle bootstrap addBundle new ConnectionManagerHolderBundle bootstrap addBundle new ReladomoBundle bootstrap addCommand new RenderCommand bootstrap addBundle new AssetsBundle bootstrap addBundle new MigrationsBundle<> @Override public DataSourceFactory getDataSourceFactory HelloWorldConfiguration configuration return configuration getNamedDataSourcesFactory getNamedDataSourceFactoryByName h2 tcp bootstrap addBundle new LiftwizardLiquibaseMigrationBundle bootstrap addBundle new ViewBundle<> @Override public Map<String Map<String String>> getViewConfiguration HelloWorldConfiguration configuration return configuration getViewRendererConfiguration bootstrap addBundle new Slf4jUncaughtExceptionHandlerBundle bootstrap addBundle new AuthFilterBundle HelloWorldApplication INFO 12 53 29 main liftwizard priority 8 liftwizard bundle ConfigLoggingBundle io liftwizard dropwizard bundle config logging ConfigLoggingBundle Inferred Dropwizard configuration template Hello %s defaultName Stranger configLogging enabled true metrics frequency 1 minute reporters metrics test example json5 io dropwizard Configuration getMetricsFactory @JsonProperty metrics public MetricsFactory getMetricsFactory return metrics false true ConfigLoggingBundle DEBUG ConfigLoggingBundle liftwizard bundle logging config <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard bundle logging config< artifactId> < dependency>"],["jackson@@ObjectMapperBundle@@adding-the-dependency","Jackson","ObjectMapperBundle","Adding the dependency","The configures the Jackson used by Dropwizard for serializing and deserializing all responses as well as for logging by bundles such as supports configuring pretty printing on or off and serialization inclusion to any value in Jackson s also turns on all json5 features turns on turns on and turns on serialization of dates and Strings To turn it on add to the list of registered bundles You ll be able to see that is working because the output of will now be pretty printed by default lives in the module","ObjectMapperBundle ObjectMapper liftwizard bundle logging config ObjectMapperBundle JsonInclude Include ObjectMapperBundle FAIL_ON_UNKNOWN_PROPERTIES STRICT_DUPLICATE_DETECTION ObjectMapperBundle @Override public void initialize Bootstrap<HelloWorldConfiguration> bootstrap JsonConfigurationFactoryFactory uses a separate ObjectMapper and can be configured earlier bootstrap setConfigurationFactoryFactory new JsonConfigurationFactoryFactory<> bootstrap addBundle new EnvironmentConfigBundle bootstrap addBundle new ObjectMapperBundle ConfigLoggingBundle uses the ObjectMapper configured by ObjectMapperBundle bootstrap addBundle new ConfigLoggingBundle ObjectMapperBundle ConfigLoggingBundle ObjectMapperBundle liftwizard bundle object mapper <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard bundle object mapper< artifactId> < dependency>"],["logging@@JerseyHttpLoggingBundle@@","Logging","JerseyHttpLoggingBundle","","The is an alternative to Jersey s Jersey s can be configured to log or not log bodies but it cannot be configured to exclude headers Since headers can include authentication tokens you may not want to log headers or only log those in an allow list The bundle can be configured include exclude request bodies include exclude response bodies allow list of headers include exclude the list of excluded header names the max body size before truncation Through code the bundle can be configured to log using different combinations of slf4j log4j logback with context in MDC or OpenTracing or a Map To turn it on add to the list of registered bundles The bundle registers filters which gather all the arguments to log A logger is passed into the constructor which abstracts over whether the logging uses logback or log4j whether the structured arguments are converted into MDC Markers or a Map The in the example above logs using slf4j with context in MDC lives in the module In order to see the logging in action we ll need to configure a log format that includes mdc and markers test example json5 Next lets turn on all the basic filters and see how they change what gets logged Logging output We can rerun and see the new logs in action Logstash encoder is a Dropwizard It sets up a file appender that logs one json object per log statement The json is formatted by logstash logback encoder and is ready to be parsed by logstash Let s add the logstash file appender to the list of configured appenders test example json5 logstash jsonl snippet","JerseyHttpLoggingBundle LoggingFeature LoggingFeature JerseyHttpLoggingBundle @Override public void initialize Bootstrap<HelloWorldConfiguration> bootstrap bootstrap setConfigurationFactoryFactory new JsonConfigurationFactoryFactory<> bootstrap addBundle new EnvironmentConfigBundle bootstrap addBundle new ObjectMapperBundle bootstrap addBundle new ConfigLoggingBundle StructuredArgumentsMDCLogger structuredLogger new StructuredArgumentsMDCLogger bootstrap getObjectMapper bootstrap addBundle new JerseyHttpLoggingBundle structuredLogger StructuredArgumentsMDCLogger var mdcLogger new StructuredArgumentsMDCLogger bootstrap getObjectMapper var logstashLogger new StructuredArgumentsLogstashEncoderLogger Consumer<StructuredArguments> structuredLogger structuredArguments > mdcLogger accept structuredArguments logstashLogger accept structuredArguments bootstrap addBundle new JerseyHttpLoggingBundle structuredLogger JerseyHttpLoggingBundle liftwizard bundle logging http <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard bundle logging http< artifactId> < dependency> src test resources test example json5 type console timeZone $ LOGGING_TIMEZONE system logFormat %highlight % 5level %cyan %date HH mm ss SSS %dwTimeZone %gray %file %line %white %thread %blue %marker %magenta %mdc %green %logger %message%n%rootException includeCallerData true IntegrationTest DEBUG 13 21 49 dw 249 io liftwizard servlet logging mdc StructuredArgumentsMDCLogger Response sent <> < response http elapsedNanos 1000000000 request http method GET request http parameters query name Dr IntegrationTest request http path full hello world request http path absolute http localhost 63842 hello world request http client port 63855 request http headers User Agent Jersey 2 25 1 HttpUrlConnection 17 0 2 request http server port 63842 request http client host 127 0 0 1 request resourceClass com example helloworld resources HelloWorldResource request http path template hello world request http server name localhost request http headers Host localhost 63842 response http headers Content Type application json response http contentType application json response http entityType com example helloworld api Saying response http status code 200 request http client address 127 0 0 1 request resourceMethod sayHello response http status phrase OK response http body id 1 content Hello Dr IntegrationTest response http contentLength 59 request http server scheme http response http status status OK response http status family SUCCESSFUL> liftwizard config logging logstash file AppenderFactory src test resources test example json5 logging level DEBUG appenders type console timeZone $ LOGGING_TIMEZONE system logFormat %highlight % 5level %cyan %date HH mm ss SSS %dwTimeZone %gray %file %line %white %thread %blue %marker %magenta %mdc %green %logger %message%n%rootException includeCallerData true type file logstash currentLogFilename logs logstash jsonl archivedLogFilenamePattern logs logstash %d jsonl includeCallerData true encoder includeContext true includeMdc true includeStructuredArguments true includedNonStructuredArguments true includeTags true prettyPrint false logs logstash jsonl"],["logging@@buffered-logging@@","Logging","Buffered Logging","","In unit tests it can be useful to suppress all logging for successful tests but still log everything when tests fail In order to accomplish this we need to buffer all logging before we know the result of the test and then flush or clear the buffer once we know the outcome BufferedAppender is the logback appender that buffers all logging until it receives a or marker You can use directly in logback configuration It requires a delegate appender for flushing declared using an lives in the module Log Markers We must log and markers to instruct to clear or flush its logs If you are using JUnit 4 or 5 you can use the included Rule or Extension to log these markers automatically JUnit 4 is a JUnit 4 that clears the buffer before all tests and flushes the buffer after failed tests It does this by logging and markers lives in the module LogMarkerTestRule Rule CLEAR FLUSH public class ExampleTest @Rule public final TestRule logMarkerTestRule new LogMarkerTestRule @Test public void smokeTest test code LogMarkerTestRule liftwizard junit rule log marker <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard junit rule log marker< artifactId> <scope>test< scope> < dependency> JUnit 5 is a JUnit 5 that clears the buffer before all tests and flushes the buffer after failed tests It does this by logging and markers lives in the module LogMarkerTestExtension Extension CLEAR FLUSH @ExtendWith LogMarkerTestExtension class public class ExampleTest @Test public void smokeTest test code LogMarkerTestExtension liftwizard junit extension log marker <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard junit extension log marker< artifactId> <scope>test< scope> < dependency> BufferedAppenderFactory The allows you to use an appender with the type where you would otherwise use in your Dropwizard configuration lives in the module Note is primarily useful for tests that use Dropwizard s JUnit 4 Rule or Dropwizard s JUnit 5 Extension JUnit 4 needs to be an inner rule when used together with DropwizardAppRule Both rules tear down logging and needs to perform its tear down first to flush its contents to the console LogMarkerTestRule LogMarkerTestRule private final TestRule logMarkerTestRule new LogMarkerTestRule private final DropwizardAppRule<MyAppConfiguration> dropwizardAppRule new DropwizardAppRule<> MyApplication class ResourceHelpers resourceFilePath test example json5 @Rule public final RuleChain ruleChain RuleChain outerRule this dropwizardAppRule around this logMarkerTestRule JUnit 5 was used as an annotation in the previous example When used together with it ought to be a field to control execution order Both extensions tear down logging and needs to perform its tear down first to flush its contents to the console LogMarkerTestExtension DropwizardAppExtension LogMarkerTestExtension @RegisterExtension final DropwizardAppExtension<MyAppConfiguration> dropwizardAppExtension new DropwizardAppExtension<> MyApplication class ResourceHelpers resourceFilePath test example json5 @RegisterExtension final LogMarkerTestExtension logMarkerTestExtension new LogMarkerTestExtension","BufferedAppender CLEAR FLUSH appender ref BufferedAppender liftwizard logging buffered appender <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard logging buffered appender< artifactId> <scope>test< scope> < dependency> CLEAR FLUSH BufferedAppender BufferedAppenderFactory buffered console logging level DEBUG appenders type buffered timeZone $ LOGGING_TIMEZONE system logFormat %highlight % 5level %cyan %date HH mm ss SSS %dwTimeZone %gray %file %line %white %thread %blue %marker %magenta %mdc %green %logger %message%n%rootException includeCallerData true BufferedAppenderFactory liftwizard config logging buffered <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard config logging buffered< artifactId> <scope>test< scope> < dependency> BufferedAppenderFactory DropwizardAppRule DropwizardAppExtension"],["logging@@filter-factories@@","Logging","Filter Factories","","Dropwizard comes with support for dynamic configuration of log filters However it ships with just a single filter the UriFilterFactory One can create logging filters that will intercept log statements before they are written and decide if theyre allowed Log filters can work on both regular statements and request log statements Liftwizard provides an improved for request logs and for plain logs RequestUrlFilterFactory is an improved version of It can filter access logs that do or don t match a list of urls To use it add a dependency on Then add a filter factory to your config with type and a list of to include or exclude The default value of is JaninoFilterFactory allows you to specify the filter condition in a snippet of Java code that gets compiled with Janino To use it add a dependency on Then add a filter factory to your config with type and a that evaluates to a boolean The default value of is","RequestUrlFilterFactory JaninoFilterFactory RequestUrlFilterFactory UriFilterFactory liftwizard config logging filter requesturl url urls onMatch ch qos logback core spi FilterReply DENY JaninoFilterFactory liftwizard config logging filter janino janino javaExpression onMatch ch qos logback core spi FilterReply DENY logging level DEBUG appenders type console timeZone $ LOGGING_TIMEZONE system logFormat %highlight % 5level %cyan %date HH mm ss SSS %dwTimeZone %gray %file %line %white %thread %blue %marker %magenta %mdc %green %logger %message%n%rootException filterFactories type janino javaExpression logger equals io liftwizard logging p6spy P6SpySlf4jLogger && mdc get liftwizard bundle equals DdlExecutorBundle onMatch DENY"],["logging@@Slf4jUncaughtExceptionHandlerBundle@@the-logs","Logging","Slf4jUncaughtExceptionHandlerBundle","The logs","is an that logs uncaught exceptions using SLF4J is a Dropwizard bundle that installs on startup When a thread is about to terminate due to an uncaught exception the Java Virtual Machine will query the thread for its UncaughtExceptionHandler using Thread getUncaughtExceptionHandler and will invoke the handler s uncaughtException method passing the thread and the exception as arguments When an uncaught exception is thrown logs the exception at the WARN level With logback configuration like this The logs look like this","Slf4jUncaughtExceptionHandler UncaughtExceptionHandler Slf4jUncaughtExceptionHandlerBundle Slf4jUncaughtExceptionHandler Slf4jUncaughtExceptionHandler <appender name Console class ch qos logback core ConsoleAppender > <encoder> <pattern>%highlight % 5level %cyan %date HH mm ss SSS $ LOGGING_TIMEZONE %gray %file %line %white %thread %blue %marker %magenta %mdc %green %logger %message%n%rootException< pattern> < encoder> < appender> WARN 12 00 00 000 Slf4jUncaughtExceptionHandler java 46 main exceptionClass io liftwizard logging slf4j uncaught exception handler Slf4jUncaughtExceptionHandlerTest RootException liftwizard error message example root liftwizard error kind io liftwizard logging slf4j uncaught exception handler Slf4jUncaughtExceptionHandlerTest RootException threadName main exceptionMessage example root liftwizard error thread main io liftwizard logging slf4j uncaught exception handler Slf4jUncaughtExceptionHandler Exception in thread main io liftwizard logging slf4j uncaught exception handler Slf4jUncaughtExceptionHandlerTest$CauseException example cause at io liftwizard logging slf4j uncaught exception handler Slf4jUncaughtExceptionHandlerTest testUncaughtException Slf4jUncaughtExceptionHandlerTest java 26 ~ test classes na 68 common frames omitted Wrapped by io liftwizard logging slf4j uncaught exception handler Slf4jUncaughtExceptionHandlerTest$RootException example root at io liftwizard logging slf4j uncaught exception handler Slf4jUncaughtExceptionHandlerTest testUncaughtException Slf4jUncaughtExceptionHandlerTest java 27 ~ test classes na"],["logging@@Slf4jUncaughtExceptionHandlerBundle@@with-dropwizard","Logging","Slf4jUncaughtExceptionHandlerBundle","With Dropwizard","To use the exception handler with Dropwizard add to the list of registered bundles And add the dependency","Slf4jUncaughtExceptionHandlerBundle @Override public void initialize Bootstrap<HelloWorldConfiguration> bootstrap bootstrap addBundle new Slf4jUncaughtExceptionHandlerBundle <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard bundle logging uncaught exception handler< artifactId> < dependency>"],["logging@@Slf4jUncaughtExceptionHandlerBundle@@without-dropwizard","Logging","Slf4jUncaughtExceptionHandlerBundle","Without Dropwizard","To use without the bundle create an instance and set it as the default uncaught exception handler And add the dependency","Slf4jUncaughtExceptionHandler Thread setDefaultUncaughtExceptionHandler new Slf4jUncaughtExceptionHandler <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard logging uncaught exception handler< artifactId> < dependency>"],["graphql@@bundle@@","Graphql","Bundle","","The extends The bundle registers the GraphIQL UI at and the GraphQL Playground UI at by delegating to This overrides the behavior of the smoketurner bundle which registers just one UI at graphiql in older versions and graphql playground in newer versions The bundle also registers two instrumentations for logging and metrics If you choose not to use the bundle you can still register the instrumentations separately To turn it on add to the list of registered bundles lives in the module","LiftwizardGraphQLBundle com smoketurner dropwizard graphql GraphQLBundle graphiql graphql playground AssetsBundle LiftwizardGraphQLBundle @Override public void initialize Bootstrap<HelloWorldConfiguration> bootstrap bootstrap setConfigurationFactoryFactory new JsonConfigurationFactoryFactory<> bootstrap addBundle new EnvironmentConfigBundle bootstrap addBundle new ObjectMapperBundle bootstrap addBundle new ConfigLoggingBundle bootstrap addBundle new JerseyHttpLoggingBundle bootstrap addBundle new LiftwizardGraphQLBundle<> builder > Set up GraphQL wiring builder scalar builder type LiftwizardGraphQLBundle liftwizard bundle graphql <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard bundle graphql< artifactId> < dependency>"],["graphql@@instrumentation-logging@@","Graphql","Instrumentation Logging","","is an implementation of from GraphQL Java that adds helpful context to slf4j s Mapped Diagnostic Context For example say that during the execution of a we execute a database query and log its sql It would be helpful to see the query in the context of the DataFetcher that executed it along with the GraphQL field and its type and the path we took through the graph on the way to this field This Instrumentation adds these fields to MDC prefixed with To turn it on either run the entire or just add to the list of instrumentations on your Here s an example of what SQL logging might look like with MDC attached when formatted by the file logstash appender lives in the module","LiftwizardGraphQLLoggingInstrumentation Instrumentation DataFetcher liftwizard graphql LiftwizardGraphQLBundle LiftwizardGraphQLLoggingInstrumentation GraphQLFactory GraphQLFactory factory var loggingInstrumentation new LiftwizardGraphQLLoggingInstrumentation List<Instrumentation> instrumentations List of loggingInstrumentation factory setInstrumentations instrumentations LiftwizardGraphQLLoggingInstrumentation liftwizard graphql instrumentation logging <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard graphql instrumentation logging< artifactId> < dependency>"],["graphql@@instrumentation-metrics@@","Graphql","Instrumentation Metrics","","is an implementation of from GraphQL Java that registers performance metrics about data fetching with Dropwizard s MetricsRegistry To turn it on either run the entire or just add to the list of instrumentations on your Annotations Next annotate the DataFetchers that you want to monitor with and or You can annotate either the method or the entire fetcher class Timers adds three timers DataFetcher s fully qualified class name get sync liftwizard graphql field GraphQL Class GraphQL field sync liftwizard graphql path path sync All three timers track the number of times each DataFetcher is called and the amount of time spent in the get method Although the timers measure the same thing they may not have identical values This would happen if the same DataFetcher is wired to multiple fields or is reached by multiple paths through the graph If your DataFetcher returns you ll get three additional timers with names ending in async instead of sync Rather than track the amount of time spent in these timers will track the amount of time until the complete Meters Timers are meters so if you want to know the number of times a fetcher is called annotate them with @Timer If you annotate your DataFetcher with the Intrumentation will add meters that track the number of items returned by the DataFetcher If the returns a or the meter will increment by the size of the Collection ExceptionMeters adds meters that track the number of times the DataFetcher throws uncaught exceptions plus the number of CompleteableFutures they return that complete exceptionally The meters have the same names as the timers but with the suffix exceptions DataFetcher s fully qualified class name get exceptions liftwizard graphql field GraphQL Class GraphQL field exceptions liftwizard graphql path path exceptions lives in the module","LiftwizardGraphQLMetricsInstrumentation Instrumentation LiftwizardGraphQLBundle LiftwizardGraphQLMetricsInstrumentation GraphQLFactory GraphQLFactory factory Clock clock Clock systemUTC var metricsInstrumentation new LiftwizardGraphQLMetricsInstrumentation this metricRegistry clock var loggingInstrumentation new LiftwizardGraphQLLoggingInstrumentation List<Instrumentation> instrumentations List of metricsInstrumentation loggingInstrumentation factory setInstrumentations instrumentations @Timed @Metered @ExceptionMetered get @Timed CompleteableFuture get CompleteableFutures @Metered DataFetcher Collection CompleteableFuture<Collection> @ExceptionMetered LiftwizardGraphQLMetricsInstrumentation liftwizard graphql instrumentation metrics <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard graphql instrumentation metrics< artifactId> < dependency>"],["graphql@@data-fetcher-async@@","Graphql","Data Fetcher Async","","is an enhanced alternative to from GraphQL Java Both have the ability to wrap a synchronous together with an and return s that execute on the also copies slf4j s Mapped Diagnostic Context to the background tasks and restores the MDC when each task completes When using Dropwizard the executor should come from its environment lives in the module","LiftwizardAsyncDataFetcher AsyncDataFetcher DataFetcher Executor CompleteableFuture Executor LiftwizardAsyncDataFetcher builder dataFetcher fieldName LiftwizardAsyncDataFetcher async dataFetcher executor ExecutorService executorService environment lifecycle executorService my data fetcher %d maxThreads maxThreads build LiftwizardAsyncDataFetcher liftwizard graphql data fetcher async <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard graphql data fetcher async< artifactId> < dependency>"],["reladomo@@reladomo-operation-compiler@@","Reladomo","Reladomo Operation Compiler","","When using Reladomo queries are usually expressed using its code generated Finder language In some situations it can be useful to have a more dynamic way of expressing queries That s where comes in It can take a String and compile it into a Reladomo Operation In this example is the equivalent query This can be used for dynamic ad hoc queries and combines well with Liftwizard s GraphQL features Compiling toString representation The syntax closely matches the representation of Reladomo s Operations with a little added flexibility In general you can call and compile the output to get back an equivalent Operation Error messages The compiler is designed to give helpful error messages on inputs that parse but don t compile For example running the compiler on might throw an error like Flexible syntax The compiler allows some flexibility in the syntax toString Alternatives `&` `&&` `and` `|` `||` `or` `<class name>` `this` `lower` `toLowerCase` `abs` `absoluteValue` ` ` ` ` `eq` ` ` `not eq` `notEq` `>` `greaterThan` `> ` `greaterThanEquals` `<` `lessThan` `< ` `lessThanEquals` `not in` `notIn` `not startsWith` `notStartsWith` `not endsWith` `notEndsWith` `not contains` `notContains` `not wildCardEquals` `wildCardNotEquals` `is null` ` null` `is not null` ` null` `all of <class name ` `all` Complete examples","Operation operation MyTypeFinder optionalString eq value and MyTypeFinder optionalInteger eq 4 MyTypeList mithraList MyTypeFinder findMany operation ReladomoOperationCompiler this stringProperty value & this integerProperty 4 MyTypeFinder finder MyTypeFinder getFinderInstance var operationText this stringProperty value & this integerProperty 4 var compiler new ReladomoOperationCompiler Operation operation compiler compile finder operationText MyTypeList mithraList MyTypeFinder findMany operation toString operation toString Operation operation String operationText operation toString Operation recompiled compiler compile finder operationText assertThat recompiled is operation this invalidAttributeName Value Could not find attribute invalidAttributeName on type MyType in this invalidAttributeName Value Valid attributes idProperty stringProperty integerProperty longProperty doubleProperty floatProperty booleanProperty instantProperty localDateProperty createdById createdOn lastUpdatedById systemFrom systemTo # Attribute types this booleanProperty true this integerProperty 4 this longProperty 5 this floatProperty 6 6 this doubleProperty 7 7 this dateProperty 2010 12 31 this timeProperty 2010 12 31T23 59 00 0Z this stringProperty Value this system 2010 12 31T23 59 00 0Z # Conjunctions this booleanProperty true & this integerProperty 4 this booleanProperty true && this integerProperty 4 this booleanProperty true and this integerProperty 4 this booleanProperty true | this integerProperty 4 this booleanProperty true || this integerProperty 4 this booleanProperty true or this integerProperty 4 # Equality operators this stringProperty Value this stringProperty Value this stringProperty is null this stringProperty null this stringProperty is not null this stringProperty null this stringProperty in Value Value2 null this stringProperty not in Value Value2 null # String operators this stringProperty endsWith Value this stringProperty contains Value this stringProperty startsWith Value this stringProperty wildCardEquals Value this stringProperty not endsWith Value this stringProperty not contains Value this stringProperty not startsWith Value this stringProperty not wildCardEquals Value # Numeric operators this stringProperty > Value this stringProperty > Value this stringProperty < Value this stringProperty < Value # Functions derived attributes toLowerCase this stringProperty value substring this stringProperty 2 3 value substring toLowerCase this stringProperty 2 3 value # Flexible number literals this floatProperty 42 0f this floatProperty 42 0d this floatProperty 42 this doubleProperty 42 0f this doubleProperty 42 0d this doubleProperty 42 this longProperty 10_000_000_000 this integerProperty 1_000_000_000 # Number date functions derived attributes abs this integerProperty 1 year this timeProperty 1999 month this timeProperty 12 dayOfMonth this timeProperty 31 year this dateProperty 1999 month this dateProperty 12 dayOfMonth this dateProperty 31 # Relationships this target value value this target exists this target not exists this target RelatedType source value value not exists # Edge points this system equalsEdgePoint"],["database@@named-data-source@@","Database","Named Data Source","","Dropwizard provides an interface called It s just a and a It s a with start stop lifecycle methods works well when you have one of them When you have multiple data sources it can be difficult to tie them together through configuration For example if you use Liquibase for migrations you d need to write code to tie specific migrations to specific data sources it cannot be done through configuration alone Liftwizard provides which is a with a name Other Liftwizard bundles expect s to be configured and refer to them by name in their own configuration In the liquibase example we could tie specific migrations to specific data sources through configuration alone Different named data sources can refer to different databases or the same database configured different ways In the following example we have one data source for Postgres and three data sources to connect to h2 over the network in memory and on disk To use named data sources start by changing the Configuration class to implement Add a field with type Add the getter setter required by the interface Now we can use the named data sources in the configuration of other bundles For example we use the data source named in the liquibase configuration","ManagedDataSource public interface ManagedDataSource extends DataSource Managed io dropwizard lifecycle Managed javax sql DataSource DataSource ManagedDataSource NamedDataSource ManagedDataSource NamedDataSource NamedDataSourceFactoryProvider public class HelloWorldConfiguration extends Configuration implements NamedDataSourceProvider other interfaces NamedDataSourcesFactory @JsonUnwrapped private @Valid @NotNull NamedDataSourcesFactory namedDataSourcesFactory new NamedDataSourcesFactory @Override @JsonProperty dataSources @JsonUnwrapped public NamedDataSourcesFactory getNamedDataSourcesFactory return this namedDataSourcesFactory @JsonProperty dataSources @JsonUnwrapped public void setNamedDataSourcesFactory NamedDataSourcesFactory namedDataSourcesFactory this namedDataSourcesFactory namedDataSourcesFactory h2 tcp"],["database@@liquibase-migrations@@","Database","Liquibase Migrations","","Dropwizard ships with a dropwizard migrations bundle The module provides you with a wrapper for Liquibase database refactoring The built in bundle provides Dropwizard Commands for a command line interface to run migrations It does not provide a way to run migrations on application startup That s where Liftwizard comes in To run migrations with Dropwizard you run a command like To run migrations with Liftwizard you run the usual command and Liftwizard will run migrations on startup There are pros and cons of tying migrations to application startup The main pros are that you don t have to remember to run migrations and that they apply to embedded databases in tests The main con is that migrations can take a long time and you may not want to block application startup To turn it on add to the list of registered bundles Change the Configuration class to implement Add a field with type Add the getter setter required by the interface Configuration The requires that you re already using named data sources Add a liquibase section to your json or yaml configuration is an array to allow multiple migrations to different data sources Each dataSourceMigration s must match a dataSource s name in the section If no is specified is the default can be or is the default are an array of Liquibase context tags With this configuration in place migrations will run on application startup","dropwizard migrations java jar hello world jar db migrate helloworld yml server LiftwizardLiquibaseMigrationBundle @Override public void initialize Bootstrap<HelloWorldConfiguration> bootstrap bootstrap addBundle new LiftwizardLiquibaseMigrationBundle LiquibaseMigrationFactoryProvider public class HelloWorldConfiguration extends Configuration implements LiquibaseMigrationFactoryProvider other interfaces LiquibaseMigrationFactory private @Valid @NotNull LiquibaseMigrationFactory liquibaseMigrationFactory new LiquibaseMigrationFactory @JsonProperty liquibase @Override public LiquibaseMigrationFactory getLiquibaseMigrationFactory return this liquibaseMigrationFactory @JsonProperty liquibase public void setLiquibaseMigrationFactory LiquibaseMigrationFactory liquibaseMigrationFactory this liquibaseMigrationFactory liquibaseMigrationFactory LiftwizardLiquibaseMigrationBundle dataSourceMigrations dataSourceName dataSources migrationFileName migrations xml migrationFileLocation classpath filesystem classpath contexts"],["auth@@dynamic-authentication-and-impersonation@@","Auth","Dynamic Authentication And Impersonation","","Liftwizard supports the dynamic configuration of dropwizard auth which enables using different authorization methods in production and tests without adding conditionals without adding any code at all For example we can configure impersonation authorization in tests with the following config Setup To get started add a dependency on and add to the registered bundles Modify the application s configuration class to implement and add a dependency on if it does not already extend Test configuration For tests you ll typically want to use header based impersonation Add a dependency on Add an list to containing just one filter of type Test code Impersonation authorization works well in tests that uses Dropwizard test utilities like or There is no change to test setup code only to the test configuration file The test code will include headers on client requests like this Whenever we use some of our Jersey resource methods will be authenticated The authenticated methods will be annotated with a security annotation such as The user principal will be passed in as a parameter and annotated like The header authorizer will take the string passed in the header in this example remove its prefix and make that string accessible via Since the header is sent on each request we can write tests involving multiple users For example we can write a test that asserts can create an entry and gets HTTP 201 Created cannot edit or delete the entry and gets HTTP 403 Forbidden can edit or delete the entry and gets HTTP 200 OK Production configuration The production authentication filter dependencies and configuration will depend on the method of authentication used in production For example the configuration to use Firebase for auth would look like this","authFilters type header header Authorization prefix Impersonation liftwizard bundle auth filter AuthFilterBundle AuthFilterFactoryProvider liftwizard config auth filter AbstractLiftwizardConfiguration liftwizard config auth filter header <dependency> <groupId>io liftwizard< groupId> <artifactId>liftwizard config auth filter header< artifactId> <scope>test< scope> < dependency> authFilters config test json5 header authFilters type header header Authorization prefix Impersonation DropwizardAppExtension LiftwizardAppExtension DropwizardAppRule @Test void smokeTest Client client this appExtension client Response response client target http localhost port api example resolveTemplate port this appExtension getLocalPort request header Authorization Impersonation User ID get add assertions here dropwizard auth @PermitAll @Auth Principal principal Impersonation User ID User ID principal getName User 1 User 2 User 1 authFilters type firebase databaseUrl https example firebaseio com firebaseConfig $ FIREBASE_CONFIG"],["testing@@testing@@","Testing","Testing","","Liftwizard includes utilities for asserting that a string equals the contents of a file slurping the file into a string file matching exact string comparison json matching json comparison rerecord mode These utilities are implemented as JUnit 4 Rules and JUnit 5 Extensions",""],["testing@@matching-files@@","Testing","Matching Files","","Liftwizard includes utilities for asserting that a string equals the contents of a file If your code has changed enough it can be more convenient to re record the test resource files and review the changes using rather than the test assertion errors To enable re record mode set the environment variable to The setup is different for the JUnit 4 Rule and JUnit 5 Extension After setup both have the same API If the file does not exist or the contents do not match an assertion error is added to an ErrorCollector If the ErrorCollector contains any errors the test fails at the end with all expected actual pairs reported together If is set to will not emit any JUnit 4 public class ExampleTest @Rule public final FileMatchRule fileMatchRule new FileMatchRule this getClass @Test public void smokeTest String resourceClassPathLocation this getClass getSimpleName txt this fileMatchRule assertFileContents resourceClassPathLocation test content JUnit 5 public class ExampleTest @RegisterExtension private final FileMatchExtension fileMatchExtension new FileMatchExtension this getClass @Test public void smokeTest String resourceClassPathLocation this getClass getSimpleName txt this fileMatchExtension assertFileContents resourceClassPathLocation test content","git diff LIFTWIZARD_FILE_MATCH_RULE_RERECORD true this fileMatchExtension assertFileContents expectedStringClassPathLocation actualString LIFTWIZARD_FILE_MATCH_RULE_RERECORD true assertFileContents AssertionErrors"],["testing@@matching-json@@","Testing","Matching Json","","Liftwizard includes utilities for asserting that a JSON string equals the contents of a file using JSON equality semantics Liftwizard delegates to JSONassert for JSON comparison The API is similar to the file matching API and re record mode is enabled with the same environment variable The setup is different for the JUnit 4 Rule and JUnit 5 Extension After setup both have the same API If the file does not exist or the contents do not match an assertion error is added to an ErrorCollector If the ErrorCollector contains any errors the test fails at the end with all expected actual pairs reported together If is set to will not emit any JUnit 4 works well with Dropwizard s JsonMatchRule DropwizardAppRule public class ExampleTest @Rule private final DropwizardAppRule<HelloWorldConfiguration> dropwizardAppRule new DropwizardAppRule<> ExampleApplication class ResourceHelpers resourceFilePath config test json5 @Rule public final JsonMatchRule jsonMatchRule new JsonMatchRule this getClass @Test public void smokeTest Response actualResponse this dropwizardAppRule client target http localhost port api example resolveTemplate port this dropwizardAppRule getLocalPort request get String actualJsonResponse actualResponse readEntity String class String expectedResponseClassPathLocation this getClass getSimpleName testName json this jsonMatchRule assertFileContents expectedResponseClassPathLocation actualJsonResponse JUnit 5 works well with Dropwizard s or Liftwizard s JsonMatchExtension DropwizardAppExtension LiftwizardAppExtension public class ExampleTest @RegisterExtension private final LiftwizardAppExtension< > appExtension this getLiftwizardAppExtension @RegisterExtension private final JsonMatchExtension jsonMatchExtension new JsonMatchExtension this getClass @Nonnull @Override private LiftwizardAppExtension< > getLiftwizardAppExtension return new LiftwizardAppExtension<> ExampleApplication class ResourceHelpers resourceFilePath config test json5 @Test public void smokeTest Response actualResponse this appExtension client target http localhost port api example resolveTemplate port this appExtension getLocalPort request get String actualJsonResponse actualResponse readEntity String class String expectedResponseClassPathLocation this getClass getSimpleName testName json this jsonMatchExtension assertFileContents expectedResponseClassPathLocation actualJsonResponse","LIFTWIZARD_FILE_MATCH_RULE_RERECORD this jsonMatchExtension assertFileContents expectedJsonClassPathLocation actualJson LIFTWIZARD_FILE_MATCH_RULE_RERECORD true assertJsonContents AssertionErrors"],["maven@@maven-best-practices@@","Maven","Maven Best Practices","","There are a number of best practices that can be handled at once by inheriting from a parent pom that takes care of them all Liftwizard ships with several parent poms that form an inheritance hierarchy is the most minimal parent pom It is meant to contain uncontroversial best practices that are applicable to all projects is a parent pom that inherits from and enables several linters and validators in profiles that are off by default is a Bill of Materials BOM that exports all modules within Liftwizard is a parent pom that inherits from selects versions of libraries related to Dropwizard applications and includes opinionated configurations for plugins Learning Maven Maven can be confusing due to the extent of the convention over configuration approach For example to answer how does maven run compilation before tests you would need to learn Plugins which are bound and enabled by default is the plugin that handles tests binds to the and phases binds to the phase In the lifecycle phases comes before which comes before None of this information appears in and little of it is logged during the build To make it easier to understand includes region markers surrounding each plugin that label the phase that the plugin is bound to The sections are sorted by phase","liftwizard minimal parent liftwizard profile parent liftwizard minimal parent liftwizard bom liftwizard parent liftwizard profile parent maven surefire plugin maven compiler plugin compile testCompile maven surefire plugin test compile testCompile test pom xml liftwizard minimal parent < region Phase 22 install > <plugin> <groupId>org apache maven plugins< groupId> <artifactId>maven install plugin< artifactId> <version>3 1 4< version> < plugin> < endregion Phase 22 install >"],["maven@@minimal-parent@@usage","Maven","Minimal Parent","Usage","The most minimal parent pom is If you are able to accept more opinionated defaults continue to The minimal parent is meant to contain uncontroversial best practices that are applicable to all projects Inherit from in your project s pom xml","liftwizard minimal parent liftwizard profile parent liftwizard minimal parent <parent> <groupId>io liftwizard< groupId> <artifactId>liftwizard minimal parent< artifactId> <version>$ liftwizard version < version> < parent>"],["maven@@minimal-parent@@what-you-will-get","Maven","Minimal Parent","What you will get","The following sections describe the best practices that are enforced by You will not need to configure these in your project s pom xml if you inherit from","liftwizard minimal parent liftwizard minimal parent"],["maven@@minimal-parent@@resource-encodings","Maven","Minimal Parent","Resource encodings","If you encounter a warning like this is because the project does not specify a character encoding scheme to configure specifies the character encoding scheme in the section of the pom xml This will become unnecessary starting with maven 4 x","WARNING Using platform encoding UTF 8 actually to copy filtered resources i e build is platform dependent maven resources plugin liftwizard minimal parent properties <project build sourceEncoding>UTF 8< project build sourceEncoding> <project reporting outputEncoding>UTF 8< project reporting outputEncoding>"],["maven@@minimal-parent@@reproducible-builds","Maven","Minimal Parent","Reproducible builds","Reproducible builds are a set of software development practices that create an independently verifiable path from source to binary code A build is reproducible if given the same source code build environment and build instructions any party can recreate bit by bit identical copies of all specified artifacts You can enable Reproducible Builds mode for plugins by specifying locking down the outputTimestamp property You will also need to run and as described in the guide to validate that builds are truly reproducible","<project build outputTimestamp>2025 08 19T16 27 43Z< project build outputTimestamp> mvn artifact check buildplan mvn verify artifact compare"],["maven@@minimal-parent@@default-goal","Maven","Minimal Parent","Default Goal","You can specify the default goal to run when you run without any arguments is a better choice than in the presence of concurrent builds that may write to simultaneously is a better choice than because developers may build up state like test files and test databases under and may not expect them to be deleted by default It s easy to run when you need it","mvn <defaultGoal>verify< defaultGoal> verify install m2 repository verify clean verify target mvn clean"],["maven@@minimal-parent@@plugins-which-are-bound-and-enabled-by-default","Maven","Minimal Parent","Plugins which are bound and enabled by default","Maven builds are configured by binding plugins to lifecycle phases Even if you don t declare any plugins in your pom xml maven will still bind some plugins to the main phases All versions of maven bind the same plugins but newer versions of maven bind newer versions of the plugins If you don t specify the versions of the plugins different members of the team could be using different versions leading to different build results on different machines It s becoming more common to lock down the version of maven itself but this wasn t always the case If you haven t specified the versions of these plugins maven enforcer plugin will log an error like To avoid this we specify versions of the plugins in the parent pom","ERROR Rule 3 org apache maven enforcer rules RequirePluginVersions failed with message Some plugins are missing valid versions or depend on Maven 3 9 5 defaults LATEST RELEASE as plugin version are not allowed org apache maven plugins maven compiler plugin The version currently in use is 3 11 0 via default lifecycle bindings org apache maven plugins maven surefire plugin The version currently in use is 3 1 2 via default lifecycle bindings org apache maven plugins maven jar plugin The version currently in use is 3 3 0 via default lifecycle bindings org apache maven plugins maven clean plugin The version currently in use is 3 2 0 via default lifecycle bindings org apache maven plugins maven install plugin The version currently in use is 3 1 1 via default lifecycle bindings org apache maven plugins maven site plugin The version currently in use is 3 12 1 via default lifecycle bindings org apache maven plugins maven resources plugin The version currently in use is 3 3 1 via default lifecycle bindings org apache maven plugins maven deploy plugin The version currently in use is 3 1 1 via default lifecycle bindings < These plugins are bound and enabled by default > < But the default version of these plugins changes with the version of maven running > < region Phase 0 clean > <plugin> <groupId>org apache maven plugins< groupId> <artifactId>maven clean plugin< artifactId> <version>3 4 1< version> < plugin> < endregion Phase 0 clean > < region Phase 6 process resources > <plugin> <groupId>org apache maven plugins< groupId> <artifactId>maven resources plugin< artifactId> <version>3 3 1< version> < plugin> < endregion Phase 6 process resources > < region Phase 7 compile > <plugin> <groupId>org apache maven plugins< groupId> <artifactId>maven compiler plugin< artifactId> <version>3 14 0< version> <configuration> < https maven apache org plugins archives maven compiler plugin 3 8 1 compile mojo html#parameters > < https stackoverflow com a 44075684 > < https docs oracle com javase 9 tools javac htm > < Generates metadata for reflection on method parameters Stores formal parameter names of constructors and methods in the generated class file so that the method java lang reflect Executable getParameters from the Reflection API can retrieve them > <parameters>true< parameters> < configuration> < plugin> < endregion Phase 7 compile > < region Phase 15 test > <plugin> <groupId>org apache maven plugins< groupId> <artifactId>maven surefire plugin< artifactId> <version>3 5 2< version> < In maven 3 9 6 and 4 x maven is able to auto detect JUnit and these dependencies are not required > < In maven 3 9 5 there is an internal exception inside surefire without these declared > < Even with newer versions of maven it is advantageous to keep these declarations > < Without them maven may only run JUnit 5 tests in a project with both JUnit 4 and 5 > <dependencies> <dependency> <groupId>org junit jupiter< groupId> <artifactId>junit jupiter engine< artifactId> <version>5 10 3< version> < dependency> <dependency> <groupId>org junit platform< groupId> <artifactId>junit platform engine< artifactId> <version>1 10 3< version> < dependency> <dependency> <groupId>org junit vintage< groupId> <artifactId>junit vintage engine< artifactId> <version>5 10 3< version> < dependency> < dependencies> <configuration> < The compiler in the server VM now provides correct stack backtraces for all cold built in exceptions For performance purposes when such an exception is thrown a few times the method may be recompiled After recompilation the compiler may choose a faster tactic using preallocated exceptions that do not provide a stack trace To disable completely the use of preallocated exceptions use this new flag XX OmitStackTraceInFastThrow > < https stackoverflow com a 4659279 > < The compiler in the server VM now provides correct stack backtraces for all cold built in exceptions For performance purposes when such an exception is thrown a few times the method may be recompiled After recompilation the compiler may choose a faster tactic using preallocated exceptions that do not provide a stack trace To disable completely the use of preallocated exceptions use this new flag XX OmitStackTraceInFastThrow > < https stackoverflow com a 4659279 > < Add argLine to allow the Jacoco plugin to append without overriding the setting > < https stackoverflow com a 39818768 > <argLine> XX OmitStackTraceInFastThrow @ argLine < argLine> <runOrder>random< runOrder> <trimStackTrace>false< trimStackTrace> <systemPropertyVariables> < Only relevant when using AssertJ Disables org assertj core util Throwables removeAssertJRelatedElementsFromStackTrace > <assertj remove assertj related elements from stack trace>false< assertj remove assertj related elements from stack trace> < systemPropertyVariables> < configuration> < plugin> < endregion Phase 15 test > < region Phase 17 package > <plugin> <groupId>org apache maven plugins< groupId> <artifactId>maven jar plugin< artifactId> <version>3 4 2< version> < plugin> < endregion Phase 17 package > < region Phase 22 install > <plugin> <groupId>org apache maven plugins< groupId> <artifactId>maven install plugin< artifactId> <version>3 1 4< version> < plugin> < endregion Phase 22 install > < region Phase 23 deploy > <plugin> <groupId>org apache maven plugins< groupId> <artifactId>maven deploy plugin< artifactId> <version>3 1 4< version> < plugin> < endregion Phase 23 deploy >"],["maven@@minimal-parent@@no-phase","Maven","Minimal Parent","No phase","The are a number of maven plugins with goals that are designed to be run interactively rather than being bound to a phase in the pom xml For example prints a visual representation of the dependencies of the project and updates the versions of dependencies in the pom xml Any maven plugin can be run from the command line with and configured using command line arguments without it appearing in the pom xml For example we can run the to list the plugins bound to each phase with this command If we configure the plugin in the pom xml we can run it with the syntax and add any configuration that would otherwise be specified with flags We configure several plugins in the parent pom xml that are not bound to any phase","mvn dependency tree mvn versions set mvn groupId artifactId version goal buildplan maven plugin mvn org codehaus mojo buildplan maven plugin 2 2 2 list mvn phase goal D mvn buildplan list < mvn versions display dependency updates > < mvn versions display plugin updates > < mvn versions display property updates > <plugin> <groupId>org codehaus mojo< groupId> <artifactId>versions maven plugin< artifactId> <version>2 18 0< version> <configuration> < Don t create pom xml versionsBackup files > <generateBackupPoms>false< generateBackupPoms> < Process all modules in a multi module build even aggregator modules without a parent child relationship > < https stackoverflow com a 49246337 23572 > <processAllModules>true< processAllModules> < configuration> < plugin> < mvn dependency tree > <plugin> <groupId>org apache maven plugins< groupId> <artifactId>maven dependency plugin< artifactId> <version>3 8 1< version> < plugin> < mvn buildplan list > < mvn buildplan list phase > < mvn buildplan list plugin > <plugin> <groupId>org codehaus mojo< groupId> <artifactId>buildplan maven plugin< artifactId> <version>2 2 2< version> <configuration> < Default value is deploy > <tasks> <task>clean< task> <task>deploy< task> < tasks> < print all phases even if no mapping to an execution is available > <showAllPhases>true< showAllPhases> < configuration> < plugin> < mvn rewrite run > < mvn rewrite dryRun > <plugin> <groupId>org openrewrite maven< groupId> <artifactId>rewrite maven plugin< artifactId> <version>6 3 0< version> <dependencies> <dependency> <groupId>org openrewrite recipe< groupId> <artifactId>rewrite static analysis< artifactId> <version>2 4 0< version> < dependency> <dependency> <groupId>org openrewrite recipe< groupId> <artifactId>rewrite migrate java< artifactId> <version>3 4 0< version> < dependency> <dependency> <groupId>org openrewrite recipe< groupId> <artifactId>rewrite testing frameworks< artifactId> <version>3 4 0< version> < dependency> <dependency> <groupId>org openrewrite recipe< groupId> <artifactId>rewrite logging frameworks< artifactId> <version>3 4 0< version> < dependency> <dependency> <groupId>org openrewrite recipe< groupId> <artifactId>rewrite apache< artifactId> <version>2 4 0< version> < dependency> < dependencies> < plugin> < mvnw wrapper wrapper Dmaven 4 0 0 alpha 7 > <plugin> <artifactId>maven wrapper plugin< artifactId> <version>3 3 2< version> < plugin> < mvn clean release clean release prepare DdevelopmentVersion 1 2 3 SNAPSHOT > <plugin> <groupId>org apache maven plugins< groupId> <artifactId>maven release plugin< artifactId> <version>3 1 1< version> <configuration> < Default value is invoker > <mavenExecutorId>forked path< mavenExecutorId> < Automatically assign submodules the parent version > <autoVersionSubmodules>true< autoVersionSubmodules> < Do not `git push` changes to the upstream repository > <pushChanges>false< pushChanges> < Format to use when generating the tag name > < Default value is @ project artifactId @ project version > <tagNameFormat>@ project version < tagNameFormat> < configuration> < plugin>"],["maven@@profile-parent@@","Maven","Profile Parent","","The profile parent pom inherits from If you are able to accept more opinionated defaults continue to The profile parent contains a number of plugins you may want to enable each wrapped individually in a maven profile Usage Inherit from in your project s pom xml What you will get The following sections describe the profiles that are added by You will not need to configure these in your project s pom xml if you inherit from You can enable the profiles using Active by default According to the docs Profiles can be active by default using a configuration like the following in a POM This profile will automatically be active for all builds unless another profile in the same POM is activated using one of the previously described methods All profiles that are active by default are automatically deactivated when a profile in the POM is activated on the command line or through its activation config This is confusing for new users who are first confused to find some profiles are enabled by default and later confused to find out that they are no longer enabled No profiles in are active by default and we recommend avoiding in your project s pom xml too maven enforcer plugin The Enforcer plugin provides goals to control certain environmental constraints such as Maven version JDK version and OS family along with many more built in rules and user created rules The dependencyConvergence rule requires that dependency version numbers converge If a project has two dependencies A and B both depending on the same artifact C this rule will fail the build if A depends on a different version of C than the version of C depended on by B The requirePluginVersions rule enforces that all plugins have a version defined either in the plugin or pluginManagement section of the pom or a parent pom The bannedDependencies rule is configured to ban all loggers except Log4j 1 x and Logback The banDuplicatePomDependencyVersions checks that there are no duplicate dependencies declared in the POM of the project Duplicate dependencies are dependencies which have the same group id artifact id type and classifier extra enforcer rules The project provides extra rules which are not part of the standard rule set The configures to use the","liftwizard minimal parent bill of materials liftwizard profile parent <parent> <groupId>io liftwizard< groupId> <artifactId>liftwizard profile parent< artifactId> <version>$ liftwizard version < version> < parent> liftwizard profile parent liftwizard profile parent mvn activate profiles <profile1> <profile2> <profiles> <profile> <id>profile name< id> <activation> <activeByDefault>true< activeByDefault> < activation> < profile> < profiles> liftwizard profile parent activeByDefault <profile> <id>prettier check< id> <build> <plugins> <plugin> <groupId>com hubspot maven plugins< groupId> <artifactId>prettier maven plugin< artifactId> <version>0 22< version> <configuration> <prettierJavaVersion>2 7 4< prettierJavaVersion> <printWidth>120< printWidth> <tabWidth>4< tabWidth> <nodePath>node< nodePath> <npmPath>npm< npmPath> < configuration> <executions> <execution> <goals> <goal>check< goal> < goals> <phase>validate< phase> < execution> < executions> < plugin> < plugins> < build> < profile> <profile> <id>prettier apply< id> <build> <plugins> <plugin> <groupId>com hubspot maven plugins< groupId> <artifactId>prettier maven plugin< artifactId> <version>0 22< version> <configuration> <prettierJavaVersion>2 7 4< prettierJavaVersion> <printWidth>120< printWidth> <tabWidth>4< tabWidth> <nodePath>node< nodePath> <npmPath>npm< npmPath> < configuration> <executions> <execution> <goals> <goal>write< goal> < goals> <phase>validate< phase> < execution> < executions> < plugin> < plugins> < build> < profile> <profile> <id>spotless check< id> <properties> <spotless check skip>false< spotless check skip> < properties> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <executions> <execution> <goals> <goal>check< goal> < goals> <phase>validate< phase> < execution> < executions> < plugin> < plugins> < build> < profile> <profile> <id>spotless apply< id> <properties> <spotless check skip>false< spotless check skip> < properties> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <executions> <execution> <goals> <goal>apply< goal> < goals> <phase>verify< phase> < execution> < executions> < plugin> < plugins> < build> < profile> <profile> <id>spotless java< id> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <configuration> <formats> <format> <toggleOffOn > <includes> <include>** * java< include> < includes> <trimTrailingWhitespace > <endWithNewline > < format> < formats> < configuration> < plugin> < plugins> < build> < profile> <profile> <id>spotless formats< id> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <configuration> <formats> <format> <toggleOffOn > <includes> <include> gitattributes< include> <include> gitignore< include> < includes> <trimTrailingWhitespace > <endWithNewline > <indent> <tabs>true< tabs> <spacesPerTab>4< spacesPerTab> < indent> < format> < formats> < configuration> < plugin> < plugins> < build> < profile> <profile> <id>spotless java sort imports< id> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <configuration> <java> <toggleOffOn> <off>@formatter off< off> <on>@formatter on< on> < toggleOffOn> <importOrder> < use an empty string for all the imports not specified explicitly | to join group without blank line and #` prefix for static imports > <order>java javax #java| #javax #< order> < importOrder> <removeUnusedImports > < java> < configuration> < plugin> < plugins> < build> < profile> <profile> <id>spotless java unused imports< id> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <configuration> <java> <toggleOffOn> <off>@formatter off< off> <on>@formatter on< on> < toggleOffOn> <removeUnusedImports > < java> < configuration> < plugin> < plugins> < build> < profile> <profile> <id>spotless prettier java< id> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <configuration> <java> <toggleOffOn> <off>@formatter off< off> <on>@formatter on< on> < toggleOffOn> <prettier> <devDependencies> <prettier>3 3 2< prettier> <prettier plugin java>2 7 4< prettier plugin java> < devDependencies> <config> <tabWidth>4< tabWidth> <printWidth>120< printWidth> <parser>java< parser> <plugins>prettier plugin java< plugins> < config> < prettier> < java> < configuration> < plugin> < plugins> < build> < profile> <profile> <id>spotless prettier java sort imports< id> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <configuration> <java> <toggleOffOn> <off>@formatter off< off> <on>@formatter on< on> < toggleOffOn> <prettier> <devDependencies> <prettier>3 3 2< prettier> <prettier plugin java>2 7 4< prettier plugin java> < devDependencies> <config> <tabWidth>4< tabWidth> <printWidth>120< printWidth> <parser>java< parser> <plugins>prettier plugin java< plugins> < config> < prettier> <importOrder> < use an empty string for all the imports not specified explicitly | to join group without blank line and #` prefix for static imports > <order>java javax #java| #javax #< order> < importOrder> <removeUnusedImports > < java> < configuration> < plugin> < plugins> < build> < profile> <profile> <id>spotless google java format< id> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <configuration> <java> <toggleOffOn> <off>@formatter off< off> <on>@formatter on< on> < toggleOffOn> <googleJavaFormat> <version>1 22 0< version> <style>AOSP< style> <reflowLongStrings>false< reflowLongStrings> <reorderImports>true< reorderImports> < googleJavaFormat> < java> < configuration> < plugin> < plugins> < build> < profile> <profile> <id>spotless java cleanthat< id> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <configuration> <java> <toggleOffOn> <off>@formatter off< off> <on>@formatter on< on> < toggleOffOn> < Cleanthat will refactor code but it may break style apply it before formatter > <cleanthat > < java> < configuration> < plugin> < plugins> < build> < profile> <profile> <id>spotless antlr< id> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <configuration> <antlr4> <toggleOffOn > <antlr4Formatter > < antlr4> < configuration> < plugin> < plugins> < build> < profile> <profile> <id>spotless sql< id> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <configuration> <sql> <toggleOffOn > <includes> <include>** * sql< include> < includes> <excludes> <exclude>** target ** * sql< exclude> < excludes> <prettier> <devDependencies> <prettier plugin sql>0 18 1< prettier plugin sql> < devDependencies> <config> <plugins>prettier plugin sql< plugins> < config> < prettier> < sql> < configuration> < plugin> < plugins> < build> < profile> <profile> <id>spotless pom< id> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <configuration> <pom> <toggleOffOn > <sortPom> <expandEmptyElements>false< expandEmptyElements> <spaceBeforeCloseEmptyElement>true< spaceBeforeCloseEmptyElement> <keepBlankLines>true< keepBlankLines> <nrOfIndentSpace>4< nrOfIndentSpace> < Sort order of elements https github com Ekryd sortpom wiki PredefinedSortOrderProfiles > <predefinedSortOrder>recommended_2008_06< predefinedSortOrder> < Custom sort order of elements https raw githubusercontent com Ekryd sortpom master sorter src main resources custom_1 xml > <sortOrderFile > < sortPom> < pom> < configuration> < plugin> < plugins> < build> < profile> <profile> <id>spotless markdown< id> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <configuration> <markdown> <toggleOffOn > <includes> <include>** * md< include> < includes> <excludes> <exclude>** target ** * md< exclude> <exclude>** src main resources archetype resources ** * md< exclude> < excludes> <flexmark > < markdown> < configuration> < plugin> < plugins> < build> < profile> <profile> <id>spotless json< id> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <configuration> <json> <toggleOffOn > <includes> <include>** * json5< include> < includes> <excludes> <exclude> * ** * json5< exclude> <exclude>** target ** * json5< exclude> <exclude>** archetype resources ** * json5< exclude> < excludes> <prettier> <config> <singleQuote>false< singleQuote> < config> < prettier> < json> < configuration> < plugin> < plugins> < build> < profile> <profile> <id>spotless yaml< id> <build> <plugins> <plugin> <groupId>com diffplug spotless< groupId> <artifactId>spotless maven plugin< artifactId> <configuration> <yaml> <toggleOffOn > <includes> <include>** * yaml< include> <include>** * yml< include> < includes> <excludes> <exclude>** target ** * yaml< exclude> <exclude>** target ** * yml< exclude> <exclude>** src main resources archetype resources ** * yml< exclude> <exclude>** src main resources archetype resources ** * yaml< exclude> < excludes> <prettier> <config> <singleQuote>false< singleQuote> < config> < prettier> < yaml> < configuration> < plugin> < plugins> < build> < profile> extra enforcer rules liftwizard minimal parent maven enforcer plugin extra enforcer rules <plugin> <groupId>org apache maven plugins< groupId> <artifactId>maven enforcer plugin< artifactId> <version>3 5 0< version> <dependencies> <dependency> <groupId>org codehaus mojo< groupId> <artifactId>extra enforcer rules< artifactId> <version>1 9 0< version> < dependency> < dependencies> < plugin>"],["temporal-data@@temporal-data-overview@@temporal-features","Temporal Data","Temporal Data Overview","Temporal features","Liftwizard has built in support for working with temporal data In this section we ll explore the various features of services that utilize this technology Note This section is language and framework agnostic If youre interested in the underlying technology Liftwizard s temporal support is built on Reladomo In an application with temporal data storage data is stored along with timestamps Here are some key features of temporal support Non destructive edits Updates and deletes won t lose any information Old data is phased out with a timestamp and new data is phased in at the same timestamp As of queries Retrieve data as it existed at a specific point in time Versioning Numbered versions of data can make working with timestamps easier As of queries can be performed by either timestamp or version number Auditing Keep track of who made each change along with the data With auditing enabled each version has a user ID in addition to its timestamps Optimistic locking Prevent multiple users from accidentally discarding each other s work with this feature APIs that perform edits require a version number as input and will fail if the input version number and current version number don t match Diff See the differences between data at two version numbers Maker Checker workflows Make and review changes before exposing them to all users Most users view the latest approved version of the data while makers checkers see the latest version In the next section we ll walk through a running example that showcases these features",""],["temporal-data@@running-example@@","Temporal Data","Running Example","","Many real life applications support temporal services Stack Overflow supports all of the features listed in the overview In this section we ll use Factorio School as a running example Factorio School and Factorio Prints are websites that lets users share designs called blueprints for the video game Factorio Liftwizard and Factorio School were both created by the same author and Factorio School leverages Liftwizard s temporal support In the next section we ll create and edit a blueprint and see how non destructive edits work",""],["temporal-data@@non-destructive-updates@@post-request-body","Temporal Data","Non Destructive Updates","POST Request Body","Blueprints are created in 3 steps starting with a test clock set at At time 1 we create an Imgur Image entry At time 2 we upload the blueprint string and receive a sha At time 3 we upload the blueprint post In this documentation we ll focus on the third step We create a blueprint post by ing to","2001 01 01 2001 01 01 2001 01 02 2001 01 03 POST api blueprint title Blueprint title blueprintString The blueprintString sha is a foreign key pointing to the blueprint data we created at time 2 sha cc341849b4086ce7b1893b366b0dc8e99ce4e595 imgurImage The imgurImage imgurId is a foreign key pointing to the Imgur Image data we created at time 1 imgurId Imgur ID 1 descriptionMarkdown Blueprint description markdown Blueprints can be tagged with multiple tags Here we have a single tag belt balancer tags This double nesting is how many to many relationships are represented This object is the BlueprintTag mapping tag This object is the tag It s part of reference data that was created earlier The category name pair is the foreign key category belt name balancer"],["temporal-data@@non-destructive-updates@@post-response-body","Temporal Data","Non Destructive Updates","POST Response Body","The response includes all the properties we sent along with server generated information","key 6ed1f638 a63c 3a54 af67 ba494f27bff2 systemFrom 2001 01 03T23 59 59Z systemTo null version number 1 systemFrom 2001 01 03T23 59 59Z systemTo null createdOn 2001 01 03T23 59 59Z createdBy userId User ID lastUpdatedBy userId User ID title Blueprint title voteSummary numberOfUpvotes 0 systemFrom 2001 01 03T23 59 59Z systemTo null blueprintString sha cc341849b4086ce7b1893b366b0dc8e99ce4e595 createdOn 2001 01 02T23 59 59Z createdBy userId User ID imgurImage imgurId Imgur ID 1 imgurType image png height 300 width 300 systemFrom 2001 01 01T23 59 59Z systemTo null descriptionMarkdown Blueprint description markdown tags systemFrom 2001 01 03T23 59 59Z systemTo null tag category belt name balancer ordinal 1 systemFrom 2000 01 01T00 00 00Z systemTo null"],["temporal-data@@non-destructive-updates@@temporal-response","Temporal Data","Non Destructive Updates","Temporal Response","Here s the same response with some temporal features labeled These will be covered in upcoming sections","The key is generated server side key 6ed1f638 a63c 3a54 af67 ba494f27bff2 The systemFrom is the time we created the blueprint post time 3 2001 01 03 systemFrom 2001 01 03T23 59 59Z The systemTo is null or infinity indicating this data is current systemTo null The version object is covered in the section on Versioning version number 1 systemFrom 2001 01 03T23 59 59Z systemTo null The createdOn createdBy and lastUpdatedBy properties are covered in the section on Auditing createdOn 2001 01 03T23 59 59Z createdBy userId User ID lastUpdatedBy userId User ID title Blueprint title voteSummary numberOfUpvotes 0 systemFrom 2001 01 03T23 59 59Z systemTo null blueprintString The request only included blueprintString sha a foreign key The response includes the whole object sha cc341849b4086ce7b1893b366b0dc8e99ce4e595 We created the blueprint data at time 2 2001 01 02 createdOn 2001 01 02T23 59 59Z createdBy userId User ID imgurImage The request only included the imgurImage id a foreign key The response includes the whole object imgurId Imgur ID 1 imgurType image png height 300 width 300 We created the Imugr image at time 1 2001 01 01 systemFrom 2001 01 01T23 59 59Z systemTo null descriptionMarkdown Blueprint description markdown tags The BlueprintTag mapping was created along with the blueprint post at time 3 2001 01 03 systemFrom 2001 01 03T23 59 59Z systemTo null tag The request only included tag category and tag name the composite foreign key The response includes the whole object category belt name balancer ordinal 1 It was created a year earlier than the Blueprint systemFrom 2000 01 01T00 00 00Z systemTo null"],["temporal-data@@non-destructive-updates@@non-destructive-updates","Temporal Data","Non Destructive Updates","Non-destructive updates","Next we update the blueprint by ing","PATCH api blueprint id version 1"],["temporal-data@@non-destructive-updates@@response","Temporal Data","Non Destructive Updates","Response","The response includes the updated properties we sent plus our first temporal updates The edits are reflected at time 4","2001 01 04 key 6ed1f638 a63c 3a54 af67 ba494f27bff2 systemFrom 2001 01 03T23 59 59Z systemFrom 2001 01 04T23 59 59Z systemTo null version number 1 systemFrom 2001 01 03T23 59 59Z number 2 systemFrom 2001 01 04T23 59 59Z systemTo null createdOn 2001 01 03T23 59 59Z createdBy userId User ID lastUpdatedBy userId User ID title Blueprint title title Edited blueprint title voteSummary numberOfUpvotes 0 systemFrom 2001 01 03T23 59 59Z systemTo null blueprintString sha cc341849b4086ce7b1893b366b0dc8e99ce4e595 createdOn 2001 01 02T23 59 59Z createdBy userId User ID imgurImage imgurId Imgur ID 1 imgurType image png height 300 width 300 systemFrom 2001 01 01T23 59 59Z systemTo null descriptionMarkdown Blueprint description markdown descriptionMarkdown Edited Blueprint description markdown tags tagCategory belt tagName balancer systemFrom 2001 01 03T23 59 59Z systemTo null tag category belt name balancer ordinal 1 systemFrom 2000 01 01T00 00 00Z systemTo null"],["temporal-data@@non-destructive-updates@@as-of-query","Temporal Data","Non Destructive Updates","As-of query","In the next section we ll perform our first as of query to prove to ourselves that no data has been lost",""],["temporal-data@@as-of-queries@@temporal-schema","Temporal Data","As Of Queries","Temporal Schema","To confirm that we have not lost any data we can perform an as of query We want to query the state of the blueprint at time 3 before the non destructive update We from We created a blueprint with key at time 3 and edited it at time 4 We can query as of any time in the range We ll use the beginning of the range Plugging these values into the template we GET The response we get from is nearly identical to the response we would have got from had we run the query at time 3 This makes sense There s a small difference in the data Some of the values that used to be are now time 4 This illustrates an important rule of temporal data All writes into the data store are immutable and append only except for the value Next we ll focus on the data store In this example we re using a relational database but these concepts apply to any data store The schema maps closely to the json examples above so if you re comfortable with the data feel free to skip ahead to the queries BLUEPRINT after create systemFrom systemTo key blueprint title descriptionMarkdown imgurImageId blueprintStringSha 2001 01 03 23 59 59 0 9999 12 01 23 59 00 0 6ed1 Blueprint title Blueprint description markdown Imgur ID 1 cc34 BLUEPRINT after update systemFrom systemTo key blueprint title descriptionMarkdown imgurImageId blueprintStringSha ` icon minus stroke red ` 2001 01 03 23 59 59 0 ` icon plus stroke green ` 2001 01 04 23 59 59 0 6ed1 ` icon minus stroke red ` Blueprint title ` icon minus stroke red ` Blueprint description markdown Imgur ID 1 cc34 ` icon plus stroke green ` 2001 01 04 23 59 59 0 9999 12 01 23 59 00 0 6ed1 ` icon plus stroke green ` Edited blueprint title ` icon plus stroke green ` Edited Blueprint description markdown Imgur ID 1 cc34 BLUEPRINT_VERSION after create systemFrom systemTo key createdById lastUpdatedById number createdOn 2001 01 03 23 59 59 0 9999 12 01 23 59 00 0 6ed1 User ID User ID 1 2001 01 03 23 59 59 0 BLUEPRINT_VERSION after update systemFrom systemTo key createdById lastUpdatedById number createdOn ` icon minus stroke red ` 2001 01 03 23 59 59 0 ` icon plus stroke green ` 2001 01 04 23 59 59 0 6ed1 User ID User ID ` icon minus stroke red ` 1 2001 01 03 23 59 59 0 ` icon plus stroke green ` 2001 01 04 23 59 59 0 9999 12 01 23 59 00 0 6ed1 User ID User ID ` icon plus stroke green ` 2 2001 01 03 23 59 59 0 Temporal Schema patterns All tables have and columns Old data is phased out by setting to now New data is phased in by setting to now The new row s and the old row s are set to the same value forming a contiguous timeline When several tables are edited within a transaction the and values are set to the same value across all tables Unchanged data is copied from the old row to the new row For very wide columns that don t change frequently it may be more efficient to split out a separate table The value of the new row is set to to indicate that the row is still active In json we had used to represent the infinity date","2001 01 03 GET api blueprint blueprintKey asOf asOf 6ed1f638 a63c 3a54 af67 ba494f27bff2 2001 01 03 2001 01 04 2001 01 03 2001 01 04 2001 01 03 api blueprint 6ed1f638 a63c 3a54 af67 ba494f27bff2 asOf 2001 01 03T23 59 59Z key 6ed1f638 a63c 3a54 af67 ba494f27bff2 systemFrom 2001 01 03T23 59 59Z systemTo null systemTo 2001 01 04T23 59 59Z version number 1 systemFrom 2001 01 03T23 59 59Z systemTo null systemTo 2001 01 04T23 59 59Z createdOn 2001 01 03T23 59 59Z createdBy userId User ID lastUpdatedBy userId User ID title Blueprint title voteSummary numberOfUpvotes 0 systemFrom 2001 01 03T23 59 59Z systemTo null blueprintString sha cc341849b4086ce7b1893b366b0dc8e99ce4e595 createdOn 2001 01 02T23 59 59Z createdBy userId User ID imgurImage imgurId Imgur ID 1 imgurType image png height 300 width 300 systemFrom 2001 01 01T23 59 59Z systemTo null descriptionMarkdown Blueprint description markdown tags tagCategory belt tagName balancer systemFrom 2001 01 03T23 59 59Z systemTo null tag category belt name balancer ordinal 1 systemFrom 2000 01 01T00 00 00Z systemTo null api blueprint blueprintKey asOf 2001 01 03T23 59 59Z api blueprint blueprintKey 2001 01 03 systemTo null 2001 01 04 systemTo systemFrom systemTo systemTo systemFrom systemFrom systemTo systemFrom systemTo systemTo 9999 12 01 23 59 00 00 null"],["temporal-data@@as-of-queries@@temporal-queries-in-sql","Temporal Data","As Of Queries","Temporal queries in SQL","As of queries are implemented in SQL by adding temporal criteria to our clause Now we can see why the infinity date is represented as If we instead used we d need to add additional criteria to our WHERE clauses Joins that are one hop away from our main table are similar Joins that are two hops away from our main table are more complicated We ll see examples of these later Temporal query patterns We perform asOf queries by adding to our clause We add this exact came criteria to every query We always all columns from the table In the examples above we used In production usage it s common to list the columns explicitly We never columns from two tables in the same query Even in the upcoming examples of joins we always from one table at a time In the next section we ll learn about adding versions and querying as of a version number","WHERE select * from BLUEPRINT t0 where t0 key 6ed1f638 a63c 3a54 af67 ba494f27bff2 and t0 system_from < 2001 01 03 23 59 59 000 and t0 system_to > 2001 01 03 23 59 59 000 9999 12 01 23 59 00 00 null select * from BLUEPRINT_TAG t0 where t0 blueprint_key 6ed1f638 a63c 3a54 af67 ba494f27bff2 and t0 system_from < 2001 01 03 23 59 59 000 and t0 system_to > 2001 01 03 23 59 59 000 where system_from < asOf and system_to > asOf WHERE SELECT SELECT * SELECT SELECT"],["temporal-data@@versioning@@query-as-of-version","Temporal Data","Versioning","Query as-of version","We ve already seen version numbers in some examples When we edited our Blueprint the version number increased from 1 to 2 When querying for previous data version numbers can be more convenient than timestamps We ll see this in the section on querying by version With versioning we bump the version number when we edit any data within the composite For Blueprints this means that we bump the version number when we edit the Blueprint itself when we replace the ImgurImage when we replace the blueprint string and when we add or remove tags We ll take a closer look in the section on Composites As of queries by version over rest are performed by adding a query parameter to the URL Our template is Plugging in the key from our running example and the version number 1 we GET This is similar to the as of query by timestamp from the previous section and the response is identical so we won t repeat it here","version GET api blueprint blueprintKey version version api blueprint 6ed1f638 a63c 3a54 af67 ba494f27bff2 version 1"],["temporal-data@@versioning@@version-queries-in-sql","Temporal Data","Versioning","Version queries in SQL","At the SQL layer queries by version number are implemented by starting with the version table This query returns version 1 which existed for the duration systemFrom systemTo key createdById lastUpdatedById number createdOn 2001 01 03 23 59 59 0 2001 01 04 23 59 59 0 6ed1 User ID User ID 1 2001 01 03 23 59 59 0 2001 01 04 23 59 59 0 9999 12 01 23 59 00 0 6ed1 User ID User ID 2 2001 01 03 23 59 59 0 At this point we take the system_from value of and use it in our subsequent queries The queries on all other tables are identical to the queries in the previous section For example to query the BLUEPRINT table","select * from BLUEPRINT_VERSION t0 where t0 key 6ed1f638 a63c 3a54 af67 ba494f27bff2 and t0 number 1 2001 01 03 2001 01 04 2001 01 03 23 59 59 000 select * from BLUEPRINT t0 where t0 key 6ed1f638 a63c 3a54 af67 ba494f27bff2 and t0 system_from < 2001 01 03 23 59 59 000 and t0 system_to > 2001 01 03 23 59 59 000"],["temporal-data@@versioning@@composites","Temporal Data","Versioning","Composites","In the previous example we edited the Blueprint s title and markdown description creating version 2 Now we ll replace the Blueprint string the ImgurImage and add two more tags We want to bump the version number just once more to 3 We update the blueprint by ing","PATCH api blueprint id version 2"],["temporal-data@@versioning@@response","Temporal Data","Versioning","Response","As desired we performed the several edits while bumping the version number by only one In addition all of the new times are identical At the SQL level all the edits were performed in a single transaction","systemFrom 2001 01 05T23 59 59Z key 6ed1f638 a63c 3a54 af67 ba494f27bff2 systemFrom 2001 01 04T23 59 59Z systemFrom 2001 01 05T23 59 59Z systemTo null version number 2 systemFrom 2001 01 04T23 59 59Z number 3 systemFrom 2001 01 05T23 59 59Z systemTo null createdOn 2001 01 03T23 59 59Z createdBy userId User ID lastUpdatedBy userId User ID title Edited blueprint title voteSummary numberOfUpvotes 0 systemFrom 2001 01 03T23 59 59Z systemTo null blueprintString sha cc341849b4086ce7b1893b366b0dc8e99ce4e595 createdOn 2001 01 02T23 59 59Z sha b11911083a0cf471a5156108389f9899675ccb0c createdOn 2001 01 03T00 00 00Z createdBy userId User ID imgurImage imgurId Imgur ID 1 imgurType image png height 300 width 300 imgurId 2nd Imgur ID imgurType 2nd Imgur Type height 200 width 200 systemFrom 2001 01 01T23 59 59Z systemTo null descriptionMarkdown Edited Blueprint description markdown tags tagCategory belt tagName balancer systemFrom 2001 01 03T23 59 59Z systemTo null tag category belt name balancer ordinal 1 systemFrom 2000 01 01T00 00 00Z systemTo null tagCategory belt tagName prioritizer systemFrom 2001 01 05T23 59 59Z systemTo null tag category belt name prioritizer ordinal 2 systemFrom 2000 01 01T00 00 00Z systemTo null tagCategory moderation tagName scheduled for deletion systemFrom 2001 01 05T23 59 59Z systemTo null tag category moderation name scheduled for deletion ordinal 18 systemFrom 2000 01 01T00 00 00Z systemTo null"],["temporal-data@@versioning@@ownership-direction","Temporal Data","Versioning","Ownership direction","sits in the middle of a many to many relationship between and In this example we considered to be part of the composite making up the Should we also consider it to be part of the as well This is our choice as application designers In this case it makes sense for to be part of the but not part of Stack Overflow makes a similar choice and s are both versioned Applying new tags to a question creates a new version of the but not the In the UML diagram above composite relationships are denoted by black diamonds Composites are subtle so let s walk through a few examples Editing a Blueprint s title or description creates a new version These are properties directly on the root type Adding or removing BlueprintTag mappings creates a new version These objects live within the composite BlueprintTag mappings don t have any mutable properties If they did editing those properties would create a new version For example if we persisted their relative ordering with an ordinal property then reordering the Blueprint s tags would create a new version When the Blueprint author changes their display name this does not create a new version The User object is not part of the composite We don t allow reassigning Blueprints to another author If we did repointing the author would create a new version This works well with a temporal schema because Blueprint createdById would be swapped","BlueprintTag Blueprint Tag BlueprintTag Blueprint Tag BlueprintTag Blueprint Tag Questions Tag Question Tag"],["temporal-data@@auditing@@","Temporal Data","Auditing","","Auditing means tracking who performed each create and update operation The version object is a convenient place to store this information Each version has a createdOn timestamp and createdBy and lastUpdatedBy fields The version table includes column createdById and lastUpdatedById that point to a user table Deletes",""]]
/*
 * Copyright 2024 znai maintainers
 * Copyright 2019 TWO SIGMA OPEN SOURCE, LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

var createStopWordFilter = function (stopWords) {
    var words = stopWords.reduce(function (memo, stopWord) {
        memo[stopWord] = stopWord
        return memo
    }, {})
    return function (token) {
        if (token && words[token.toString()] !== token.toString()) return token
    }
}

var stopWordFilter = createStopWordFilter([
    'a',
    'am',
    'an',
    'at',
    'be',
    'so',
    'to'
])

znaiSearchIdx = lunr(function () {
    this.pipeline.remove(lunr.stemmer)
    this.ref('id')
    this.field('section')
    this.field('pageTitle')
    this.field('pageSection')
    this.field('textStandard')
    this.field('textHigh')

    this.metadataWhitelist = ['position']

    znaiSearchData.forEach(function (e) {
        this.add({
            id: e[0],
            section: e[1],
            pageTitle: e[2],
            pageSection: e[3],
            textStandard: e[4],
            textHigh: e[5],
        })
    }, this)
})
